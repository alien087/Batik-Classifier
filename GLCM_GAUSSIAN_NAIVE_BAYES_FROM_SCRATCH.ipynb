{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import timeit\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "import matplotlib.image as mpimg \n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_8bit_to_3bit = [i // 32 for i in range(256)]\n",
    "model = {}\n",
    "model_test = {}\n",
    "neighbor = 3\n",
    "time_modelling_start = timeit.default_timer()\n",
    "model[\"cap\"] = []\n",
    "model[\"tulis\"] = []\n",
    "model_test[\"cap\"] = []\n",
    "model_test[\"tulis\"] = []\n",
    "mean = {}\n",
    "variance = {}\n",
    "mean[\"tulis\"] = []\n",
    "variance[\"tulis\"] = []\n",
    "mean[\"cap\"] = []\n",
    "variance[\"cap\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre Processing\n",
    "def load_img(img_path):\n",
    "    return Image.open(img_path).convert('L')\n",
    "\n",
    "def get_img_size(img):\n",
    "    return img.size\n",
    "\n",
    "def print_img(img):\n",
    "    plt.imshow(img)\n",
    "    \n",
    "def get_img_colors(img, sampling_count):\n",
    "    img_width, img_height = get_img_size(img)\n",
    "    \n",
    "    sample_width = int(img_width / sampling_count)\n",
    "    sample_height = int(img_height / sampling_count)\n",
    "    \n",
    "    half_sample_width = int(sample_width/2)\n",
    "    half_sample_height = int(sample_height/2)\n",
    "\n",
    "    img_colors = []\n",
    "\n",
    "    width_constraint = img_width - (2 * sample_width)\n",
    "    height_constraint = img_height - (2 * sample_height)\n",
    "   \n",
    "    row = 0\n",
    "    for point_x in range(half_sample_width, img_width, sample_width):\n",
    "        if(row == sampling_count):\n",
    "            break\n",
    "        column = 0\n",
    "        for point_y in range(half_sample_height, img_height, sample_height):\n",
    "            if(column == sampling_count):\n",
    "                break\n",
    "            img_colors.append(img.getpixel((point_x, point_y)))\n",
    "                \n",
    "            column += 1\n",
    "                \n",
    "        row += 1\n",
    "            \n",
    "    return img_colors\n",
    "\n",
    "def construct_img(img_colors, img_dimension, sampling_count):\n",
    "    img_new = Image.new('RGB', (img_dimension), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img_new)\n",
    "    \n",
    "    img_new_width = img_dimension[0]\n",
    "    img_new_height = img_dimension[1]\n",
    "\n",
    "    sample_width = int(img_new_width/sampling_count)\n",
    "    sample_height = int(img_new_height/sampling_count)\n",
    "    loop_count = 0\n",
    "\n",
    "    img_colors_len = len(img_colors)\n",
    "\n",
    "    for w in range(0, img_new_width, sample_width):\n",
    "        for h in range(0, img_new_height, sample_height):\n",
    "            if(loop_count == img_colors_len):\n",
    "                break\n",
    "            \n",
    "            current_color = (img_colors[loop_count], img_colors[loop_count], img_colors[loop_count])\n",
    "            draw.rectangle((w, h, w+sample_width, h+sample_height), fill=current_color)\n",
    "            loop_count += 1\n",
    "    \n",
    "    return img_new\n",
    "\n",
    "def get_3bit_colors(img_colors):\n",
    "    loop_count = 0\n",
    "    \n",
    "    for img_color in img_colors:\n",
    "        img_colors[loop_count] = map_8bit_to_3bit[img_color]\n",
    "        \n",
    "        loop_count += 1\n",
    "        \n",
    "    return img_colors\n",
    "\n",
    "def get_img_matrix(img_colors):\n",
    "    img_matrix = [] \n",
    "    loop_count = 0\n",
    "    \n",
    "    loop_count = 0\n",
    "    img_square_dimension = int(math.sqrt(len(img_colors)))\n",
    "    \n",
    "    for row in range(img_square_dimension):\n",
    "        temp_row = []\n",
    "        for col in range(img_square_dimension):\n",
    "            temp_row.append(img_colors[loop_count])\n",
    "            \n",
    "            loop_count += 1\n",
    "        img_matrix.append(temp_row)\n",
    "        \n",
    "    return img_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features Extraction\n",
    "def feature_extract(img, sampling_count, class_name):\n",
    "    glcm_component=[]\n",
    "    img_colors = get_img_colors(img, sampling_count)\n",
    "    img_3bit_colors = get_3bit_colors(img_colors)\n",
    "    img_matrix = get_img_matrix(img_3bit_colors)\n",
    "    glcm_matrix=greycomatrix(img_matrix, distances=[1], angles=[0], levels=12, symmetric=False, normed=False)\n",
    "    component = ['contrast', 'homogeneity', 'energy', 'correlation', 'ASM', 'dissimilarity']\n",
    "    for x in component:\n",
    "        glcm_component.append(greycoprops(glcm_matrix, x)[0][0])\n",
    "    glcm_component.append(class_name)\n",
    "    return(glcm_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelling\n",
    "def get_class_names(training_folder_path):\n",
    "    return os.listdir(training_folder_path)\n",
    "\n",
    "def make_a_model(class_name, features, learning_rate):\n",
    "    random_splitter = random.uniform(0, 1)\n",
    "    if(random_splitter <= learning_rate):\n",
    "        model[class_name].append(features)\n",
    "    else:\n",
    "        model_test[class_name].append(features)\n",
    "        \n",
    "def to_dataframe(model):\n",
    "    models = pd.DataFrame(model['cap'] + model['tulis'], columns=['contrast', 'homogeneity', 'energy', 'correlation', 'ASM', 'dissimilarity', 'class'])\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification\n",
    "def naive_bayes(image, cap_probability, tulis_probability):\n",
    "    prob = 1\n",
    "    probability = 0.00\n",
    "    for class_name in class_names:\n",
    "        if(class_name==\"tulis\"):\n",
    "            prob=tulis_probability\n",
    "        elif(class_name==\"cap\"):\n",
    "            prob=cap_probability\n",
    "        for i in range(5):\n",
    "            a = (image[i]-mean[class_name][i])**2/(2*variance[class_name][i])\n",
    "            b = 1/(np.sqrt(2*3.14*variance[class_name][i]))\n",
    "            prob=prob * (b* np.exp(0-a))\n",
    "       \n",
    "        if(prob>probability):\n",
    "            probability = prob\n",
    "            probability_class = class_name\n",
    "        prob=1\n",
    "    return probability_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "def validate(sampling_count):\n",
    "    right = 0\n",
    "    total = 0\n",
    "    for class_name in class_names:\n",
    "        validate_img_paths = glob.glob(validation_folder_path + class_name + '/' +img_type)\n",
    "        for images in validate_img_paths:\n",
    "            img = load_img(images)\n",
    "            training_img_class_name = class_name\n",
    "            image = feature_extract(img, sampling_count, training_img_class_name)\n",
    "            predict = naive_bayes(image)\n",
    "            class_image = class_name\n",
    "            if(predict == class_name):\n",
    "                   right+=1\n",
    "            total +=1\n",
    "        accuracy = (right/total) * 100\n",
    "    print(\"Accuracy: \" + str(accuracy) +\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "\n",
    "def testing(cap_probability, tulis_probability):\n",
    "    right = 0\n",
    "    total = 0\n",
    "    for class_name in class_names:\n",
    "        for image in model_test[class_name]:\n",
    "            predict = naive_bayes(image, cap_probability, tulis_probability)\n",
    "            class_image = class_name\n",
    "            if(predict == class_name):\n",
    "                   right+=1\n",
    "            total +=1\n",
    "    accuracy = (right/total) * 100\n",
    "    print(\"Accuracy: \" + str(accuracy) +\"%\")\n",
    "    \n",
    "    \n",
    "def testing_out(sampling_count):\n",
    "    testing_img_paths = glob.glob(test_folder_path + '/' + img_type)\n",
    "    for testing_img_path in testing_img_paths:\n",
    "        imgs = load_img(testing_img_path)\n",
    "        predict_class = knn(imgs, sampling_count, neighbor)\n",
    "        print(\"Categorized as \" + predict_class)\n",
    "        plt.imshow(Image.open(testing_img_path))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testings():\n",
    "    total={}\n",
    "    total[\"tulis\"] = models.loc[models['class'] == 'tulis']\n",
    "    total[\"cap\"] = models.loc[models['class'] == 'cap']\n",
    "    mean[\"tulis\"] = []\n",
    "    variance[\"tulis\"] = []\n",
    "    mean[\"cap\"] = []\n",
    "    variance[\"cap\"] = []\n",
    "    tulis_probability = (total[\"tulis\"].count()/models.count())[0]\n",
    "    cap_probability = (total[\"cap\"].count()/models.count())[0]\n",
    "    print(tulis_probability, cap_probability)\n",
    "    for a in [\"tulis\", \"cap\"]:\n",
    "        for b in ['contrast', 'homogeneity', 'energy', 'correlation', 'ASM', 'dissimilarity']:\n",
    "            mean[a].append(total[a][b].mean())\n",
    "            variance[a].append(total[a][b].var())\n",
    "    \n",
    "    testing(cap_probability, tulis_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4583333333333333 0.5416666666666666\n",
      "Accuracy: 75.96153846153845%\n",
      "0.4653014789533561 0.534698521046644\n",
      "Accuracy: 73.57512953367875%\n",
      "0.46924829157175396 0.530751708428246\n",
      "Accuracy: 72.16494845360825%\n",
      "0.46490218642117376 0.5350978135788262\n",
      "Accuracy: 73.15270935960592%\n",
      "0.46813388353966073 0.5318661164603393\n",
      "Accuracy: 73.74749498997996%\n",
      "Time elapsed to make this model is 72.6440121 seconds.\n"
     ]
    }
   ],
   "source": [
    "#Training Testing\n",
    "\n",
    "learning_rate = 0.8\n",
    "sampling_count = 128\n",
    "img_type = '*.jpg'\n",
    "root_path = './'\n",
    "training_folder_path = root_path + 'glcm/training/'\n",
    "validation_folder_path = root_path + 'glcm/validation/'\n",
    "test_folder_path = root_path + 'glcm/test/'\n",
    "\n",
    "class_names = get_class_names(training_folder_path)\n",
    "\n",
    "for i in range(5):\n",
    "    for class_name in class_names:\n",
    "        training_img_paths = glob.glob(training_folder_path + class_name + '/' + img_type)\n",
    "        for training_img_path in training_img_paths:\n",
    "            training_img = load_img(training_img_path)\n",
    "            training_img_class_name = class_name\n",
    "            feature = feature_extract(training_img, sampling_count, training_img_class_name)\n",
    "            make_a_model(class_name, feature, learning_rate)\n",
    "        \n",
    "    models = to_dataframe(model)\n",
    "    models_test = to_dataframe(model_test)\n",
    "\n",
    "    testings()\n",
    "validate(128)\n",
    "\n",
    "\n",
    "\n",
    "time_modelling_stop = timeit.default_timer()\n",
    "print('Time elapsed to make this model is ' + str(time_modelling_stop - time_modelling_start) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = models.iloc[:, [0, 5]].values  \n",
    "y = models.iloc[:, 6].values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.70091043, 0.765625  ],\n",
       "       [1.4824065 , 0.72637795],\n",
       "       [1.93307087, 0.87881398],\n",
       "       ...,\n",
       "       [1.61226624, 0.72926919],\n",
       "       [1.64886811, 0.72404035],\n",
       "       [1.92550443, 0.82105069]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "sc = StandardScaler()  \n",
    "x_train = sc.fit_transform(x_train)  \n",
    "x_test = sc.transform(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB  \n",
    "classifier = GaussianNB()  \n",
    "classifier.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7014925373134329"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
