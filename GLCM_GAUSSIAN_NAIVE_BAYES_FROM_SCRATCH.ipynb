{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import timeit\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "import matplotlib.image as mpimg \n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "from PIL import ImageEnhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_8bit_to_3bit = [i // 32 for i in range(256)]\n",
    "model = {}\n",
    "model_test = {}\n",
    "neighbor = 3\n",
    "time_modelling_start = timeit.default_timer()\n",
    "model[\"cap\"] = []\n",
    "model[\"tulis\"] = []\n",
    "model_test[\"cap\"] = []\n",
    "model_test[\"tulis\"] = []\n",
    "mean = {}\n",
    "variance = {}\n",
    "mean[\"tulis\"] = []\n",
    "variance[\"tulis\"] = []\n",
    "mean[\"cap\"] = []\n",
    "variance[\"cap\"] = []\n",
    "a1 =0\n",
    "b1=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset():\n",
    "    global map_8bit_to_3bit\n",
    "    global model\n",
    "    global model_test\n",
    "    global time_modelling_start\n",
    "    global mean\n",
    "    global variance\n",
    "    global a1\n",
    "    global b1\n",
    "    map_8bit_to_3bit = [i // 32 for i in range(256)]\n",
    "    model = {}\n",
    "    model_test = {}\n",
    "    neighbor = 3\n",
    "    time_modelling_start = timeit.default_timer()\n",
    "    model[\"cap\"] = []\n",
    "    model[\"tulis\"] = []\n",
    "    model_test[\"cap\"] = []\n",
    "    model_test[\"tulis\"] = []\n",
    "    mean = {}\n",
    "    variance = {}\n",
    "    mean[\"tulis\"] = []\n",
    "    variance[\"tulis\"] = []\n",
    "    mean[\"cap\"] = []\n",
    "    variance[\"cap\"] = []\n",
    "    a1 =0\n",
    "    b1=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre Processing\n",
    "def load_img(img_path):\n",
    "    return Image.open(img_path).convert('L')\n",
    "\n",
    "def get_img_size(img):\n",
    "    return img.size\n",
    "\n",
    "def print_img(img):\n",
    "    plt.imshow(img)\n",
    "    \n",
    "def get_img_colors(img):\n",
    "    return list(img.getdata())\n",
    "\n",
    "def construct_img(img_colors, img_dimension, sampling_count):\n",
    "    img_new = Image.new('RGB', (img_dimension), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img_new)\n",
    "    \n",
    "    img_new_width = img_dimension[0]\n",
    "    img_new_height = img_dimension[1]\n",
    "\n",
    "    sample_width = int(img_new_width/sampling_count)\n",
    "    sample_height = int(img_new_height/sampling_count)\n",
    "    loop_count = 0\n",
    "\n",
    "    img_colors_len = len(img_colors)\n",
    "\n",
    "    for w in range(0, img_new_width, sample_width):\n",
    "        for h in range(0, img_new_height, sample_height):\n",
    "            if(loop_count == img_colors_len):\n",
    "                break\n",
    "            \n",
    "            current_color = (img_colors[loop_count], img_colors[loop_count], img_colors[loop_count])\n",
    "            draw.rectangle((w, h, w+sample_width, h+sample_height), fill=current_color)\n",
    "            loop_count += 1\n",
    "    \n",
    "    return img_new\n",
    "\n",
    "def get_3bit_colors(img):\n",
    "    img_colors = get_img_colors(img)\n",
    "    loop_count = 0\n",
    "    \n",
    "    for img_color in img_colors:\n",
    "        img_colors[loop_count] = map_8bit_to_3bit[img_color]\n",
    "        \n",
    "        loop_count += 1\n",
    "        \n",
    "    return img_colors\n",
    "\n",
    "def get_img_matrix(img_colors):\n",
    "    img_matrix = [] \n",
    "    loop_count = 0\n",
    "    \n",
    "    loop_count = 0\n",
    "    img_square_dimension = int(math.sqrt(len(img_colors)))\n",
    "    \n",
    "    for row in range(img_square_dimension):\n",
    "        temp_row = []\n",
    "        for col in range(img_square_dimension):\n",
    "            temp_row.append(img_colors[loop_count])\n",
    "            \n",
    "            loop_count += 1\n",
    "        img_matrix.append(temp_row)\n",
    "        \n",
    "    return img_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features Extraction\n",
    "def feature_extract(img, sampling_count, class_name):\n",
    "    glcm_component=[]\n",
    "    img_3bit_colors = get_3bit_colors(img)\n",
    "    img_matrix = get_img_matrix(img_3bit_colors)\n",
    "    glcm_matrix=greycomatrix(img_matrix, distances=[1], angles=[0], levels=12, symmetric=False, normed=False)\n",
    "    component = ['contrast', 'homogeneity', 'energy', 'correlation', 'ASM', 'dissimilarity']\n",
    "    for x in component:\n",
    "        glcm_component.append(greycoprops(glcm_matrix, x)[0][0])\n",
    "    glcm_component.append(class_name)\n",
    "    return(glcm_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelling\n",
    "def get_class_names(training_folder_path):\n",
    "    return os.listdir(training_folder_path)\n",
    "\n",
    "def make_a_model(class_name, features, learning_rate):\n",
    "    random_splitter = random.uniform(0, 1)\n",
    "    if(random_splitter <= learning_rate):\n",
    "        model[class_name].append(features)\n",
    "    else:\n",
    "        model_test[class_name].append(features)\n",
    "        \n",
    "def to_dataframe(model):\n",
    "    models = pd.DataFrame(model['cap'] + model['tulis'], columns=['contrast', 'homogeneity', 'energy', 'correlation', 'ASM', 'dissimilarity', 'class'])\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification\n",
    "def naive_bayes(image, cap_probability, tulis_probability):\n",
    "    prob = 1\n",
    "    probability = 0.00\n",
    "    for class_name in class_names:\n",
    "        if(class_name==\"tulis\"):\n",
    "            prob=tulis_probability\n",
    "        elif(class_name==\"cap\"):\n",
    "            prob=cap_probability\n",
    "        for i in range(5):\n",
    "            a = (image[i]-mean[class_name][i])**2/(2*variance[class_name][i])\n",
    "            b = 1/(np.sqrt(2*3.14*variance[class_name][i]))\n",
    "            prob=prob * (b* np.exp(0-a))\n",
    "       \n",
    "        if(prob>probability):\n",
    "            probability = prob\n",
    "            probability_class = class_name\n",
    "        prob=1\n",
    "    return probability_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "\n",
    "def testing(cap_probability, tulis_probability):\n",
    "    right = 0\n",
    "    total = 0\n",
    "    for class_name in class_names:\n",
    "        for image in model_test[class_name]:\n",
    "            predict = naive_bayes(image, cap_probability, tulis_probability)\n",
    "            class_image = class_name\n",
    "            if(predict == class_name):\n",
    "                   right+=1\n",
    "            total +=1\n",
    "    accuracy = (right/total) * 100\n",
    "    print(\"Accuracy: \" + str(accuracy) +\"%\\n\")\n",
    "    \n",
    "    \n",
    "def testing_out(sampling_count):\n",
    "    testing_img_paths = glob.glob(test_folder_path + '/' + img_type)\n",
    "    for testing_img_path in testing_img_paths:\n",
    "        imgs = load_img(testing_img_path)\n",
    "        predict_class = knn(imgs, sampling_count, neighbor)\n",
    "        print(\"Categorized as \" + predict_class)\n",
    "        plt.imshow(Image.open(testing_img_path))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testings():\n",
    "    global a1, b1\n",
    "    total={}\n",
    "    total[\"tulis\"] = models.loc[models['class'] == 'tulis']\n",
    "    total[\"cap\"] = models.loc[models['class'] == 'cap']\n",
    "    mean[\"tulis\"] = []\n",
    "    variance[\"tulis\"] = []\n",
    "    mean[\"cap\"] = []\n",
    "    variance[\"cap\"] = []\n",
    "    tulis_probability = (total[\"tulis\"].count()/models.count())[0]\n",
    "    cap_probability = (total[\"cap\"].count()/models.count())[0]\n",
    "    a1=tulis_probability\n",
    "    b1=cap_probability\n",
    "    for a in [\"tulis\", \"cap\"]:\n",
    "        for b in ['contrast', 'homogeneity', 'energy', 'correlation', 'ASM']:\n",
    "            mean[a].append(total[a][b].mean())\n",
    "            variance[a].append(total[a][b].var())\n",
    "    \n",
    "    testing(cap_probability, tulis_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "def validate(sampling_count, a, b):\n",
    "   \n",
    "    right = 0\n",
    "    total = 0\n",
    "    for class_name in class_names:\n",
    "        validate_img_paths = glob.glob(validation_folder_path + class_name + '/' +img_type)\n",
    "        for images in validate_img_paths:\n",
    "            img = load_img(images)\n",
    "            enhancer = ImageEnhance.Sharpness(img)\n",
    "            img = enhancer.enhance(1.5)\n",
    "            training_img_class_name = class_name\n",
    "            image = feature_extract(img, sampling_count, training_img_class_name)\n",
    "            predict = naive_bayes(image,a,b)\n",
    "            class_image = class_name\n",
    "            if(predict == class_name):\n",
    "                   right+=1\n",
    "            total +=1\n",
    "        accuracy = (right/total) * 100\n",
    "    print(\"Accuracy: \" + str(accuracy) +\"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch ke-1 \n",
      "Accuracy: 78.21782178217822%\n",
      "\n",
      "Epoch ke-2 \n",
      "Accuracy: 74.17840375586854%\n",
      "\n",
      "Epoch ke-3 \n",
      "Accuracy: 74.61300309597523%\n",
      "\n",
      "Epoch ke-4 \n",
      "Accuracy: 73.1934731934732%\n",
      "\n",
      "Epoch ke-5 \n",
      "Accuracy: 74.08088235294117%\n",
      "\n",
      "Epoch ke-6 \n",
      "Accuracy: 74.24242424242425%\n",
      "\n",
      "Epoch ke-7 \n",
      "Accuracy: 75.51813471502591%\n",
      "\n",
      "Epoch ke-8 \n",
      "Accuracy: 74.97155858930603%\n",
      "\n",
      "Epoch ke-9 \n",
      "Accuracy: 75.65656565656566%\n",
      "\n",
      "Epoch ke-10 \n",
      "Accuracy: 74.93138151875571%\n",
      "\n",
      "Iterasi ke-1 \n",
      "Accuracy: 76.953125%\n",
      "\n",
      "Time elapsed to make this model is 554.6241404 seconds.\n",
      "Epoch ke-1 \n",
      "Accuracy: 71.875%\n",
      "\n",
      "Epoch ke-2 \n",
      "Accuracy: 73.68421052631578%\n",
      "\n",
      "Epoch ke-3 \n",
      "Accuracy: 71.29032258064515%\n",
      "\n",
      "Epoch ke-4 \n",
      "Accuracy: 72.41379310344827%\n",
      "\n",
      "Epoch ke-5 \n",
      "Accuracy: 72.86821705426357%\n",
      "\n",
      "Epoch ke-6 \n",
      "Accuracy: 71.49758454106279%\n",
      "\n",
      "Epoch ke-7 \n",
      "Accuracy: 72.29080932784636%\n",
      "\n",
      "Epoch ke-8 \n",
      "Accuracy: 72.55594817432274%\n",
      "\n",
      "Epoch ke-9 \n",
      "Accuracy: 71.07180020811654%\n",
      "\n",
      "Epoch ke-10 \n",
      "Accuracy: 72.55813953488372%\n",
      "\n",
      "Iterasi ke-2 \n",
      "Accuracy: 75.390625%\n",
      "\n",
      "Time elapsed to make this model is 507.64008749999994 seconds.\n",
      "Epoch ke-1 \n",
      "Accuracy: 75.75757575757575%\n",
      "\n",
      "Epoch ke-2 \n",
      "Accuracy: 78.32512315270937%\n",
      "\n",
      "Epoch ke-3 \n",
      "Accuracy: 79.01639344262294%\n",
      "\n",
      "Epoch ke-4 \n",
      "Accuracy: 77.88697788697789%\n",
      "\n",
      "Epoch ke-5 \n",
      "Accuracy: 77.36220472440945%\n",
      "\n",
      "Epoch ke-6 \n",
      "Accuracy: 75.72815533980582%\n",
      "\n",
      "Epoch ke-7 \n",
      "Accuracy: 75.30695770804911%\n",
      "\n",
      "Epoch ke-8 \n",
      "Accuracy: 74.58033573141488%\n",
      "\n",
      "Epoch ke-9 \n",
      "Accuracy: 74.94669509594883%\n",
      "\n",
      "Epoch ke-10 \n",
      "Accuracy: 75.02392344497608%\n",
      "\n",
      "Iterasi ke-3 \n",
      "Accuracy: 76.171875%\n",
      "\n",
      "Time elapsed to make this model is 509.4166852000003 seconds.\n"
     ]
    }
   ],
   "source": [
    "#Main\n",
    "\n",
    "learning_rate = 0.8\n",
    "sampling_count = 128\n",
    "img_type = '*.jpg'\n",
    "root_path = './'\n",
    "training_folder_path = root_path + 'glcm/training/'\n",
    "validation_folder_path = root_path + 'glcm/validation/'\n",
    "test_folder_path = root_path + 'glcm/test/'\n",
    "\n",
    "class_names = get_class_names(training_folder_path)\n",
    "\n",
    "for j in range(3):\n",
    "    for i in range(10):\n",
    "        for class_name in class_names:\n",
    "            training_img_paths = glob.glob(training_folder_path + class_name + '/' + img_type)\n",
    "            for training_img_path in training_img_paths:\n",
    "                training_img = load_img(training_img_path)\n",
    "                enhancer = ImageEnhance.Sharpness(training_img)\n",
    "                training_img = enhancer.enhance(1.5)\n",
    "                training_img_class_name = class_name\n",
    "                feature = feature_extract(training_img, sampling_count, training_img_class_name)\n",
    "                make_a_model(class_name, feature, learning_rate)\n",
    "\n",
    "        models = to_dataframe(model)\n",
    "        models_test = to_dataframe(model_test)\n",
    "        print(\"Epoch ke-\"+ str(i+1) + \" \")\n",
    "        testings()\n",
    "        \n",
    "    print(\"Iterasi ke-\"+ str(j+1) + \" \")\n",
    "    validate(128,a1,b1)\n",
    "    time_modelling_stop = timeit.default_timer()\n",
    "    print('Time elapsed to make this model is ' + str(time_modelling_stop - time_modelling_start) + ' seconds.')\n",
    "    reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
