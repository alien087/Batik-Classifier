{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import timeit\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "import matplotlib.image as mpimg \n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_8bit_to_3bit = [i // 32 for i in range(256)]\n",
    "model = {}\n",
    "model_test = {}\n",
    "neighbor = 3\n",
    "time_modelling_start = timeit.default_timer()\n",
    "model[\"cap\"] = []\n",
    "model[\"tulis\"] = []\n",
    "model_test[\"cap\"] = []\n",
    "model_test[\"tulis\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre Processing\n",
    "def load_img(img_path):\n",
    "    return Image.open(img_path).convert('L')\n",
    "\n",
    "def get_img_size(img):\n",
    "    return img.size\n",
    "\n",
    "def print_img(img):\n",
    "    plt.imshow(img)\n",
    "    \n",
    "def get_img_colors(img, sampling_count):\n",
    "    img_width, img_height = get_img_size(img)\n",
    "    \n",
    "    sample_width = int(img_width / sampling_count)\n",
    "    sample_height = int(img_height / sampling_count)\n",
    "    \n",
    "    half_sample_width = int(sample_width/2)\n",
    "    half_sample_height = int(sample_height/2)\n",
    "\n",
    "    img_colors = []\n",
    "\n",
    "    width_constraint = img_width - (2 * sample_width)\n",
    "    height_constraint = img_height - (2 * sample_height)\n",
    "   \n",
    "    row = 0\n",
    "    for point_x in range(half_sample_width, img_width, sample_width):\n",
    "        if(row == sampling_count):\n",
    "            break\n",
    "        column = 0\n",
    "        for point_y in range(half_sample_height, img_height, sample_height):\n",
    "            if(column == sampling_count):\n",
    "                break\n",
    "            img_colors.append(img.getpixel((point_x, point_y)))\n",
    "                \n",
    "            column += 1\n",
    "                \n",
    "        row += 1\n",
    "            \n",
    "    return img_colors\n",
    "\n",
    "def construct_img(img_colors, img_dimension, sampling_count):\n",
    "    img_new = Image.new('RGB', (img_dimension), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img_new)\n",
    "    \n",
    "    img_new_width = img_dimension[0]\n",
    "    img_new_height = img_dimension[1]\n",
    "\n",
    "    sample_width = int(img_new_width/sampling_count)\n",
    "    sample_height = int(img_new_height/sampling_count)\n",
    "    loop_count = 0\n",
    "\n",
    "    img_colors_len = len(img_colors)\n",
    "\n",
    "    for w in range(0, img_new_width, sample_width):\n",
    "        for h in range(0, img_new_height, sample_height):\n",
    "            if(loop_count == img_colors_len):\n",
    "                break\n",
    "            \n",
    "            current_color = (img_colors[loop_count], img_colors[loop_count], img_colors[loop_count])\n",
    "            draw.rectangle((w, h, w+sample_width, h+sample_height), fill=current_color)\n",
    "            loop_count += 1\n",
    "    \n",
    "    return img_new\n",
    "\n",
    "def get_3bit_colors(img_colors):\n",
    "    loop_count = 0\n",
    "    \n",
    "    for img_color in img_colors:\n",
    "        img_colors[loop_count] = map_8bit_to_3bit[img_color]\n",
    "        \n",
    "        loop_count += 1\n",
    "        \n",
    "    return img_colors\n",
    "\n",
    "def get_img_matrix(img_colors):\n",
    "    img_matrix = [] \n",
    "    loop_count = 0\n",
    "    \n",
    "    loop_count = 0\n",
    "    img_square_dimension = int(math.sqrt(len(img_colors)))\n",
    "    \n",
    "    for row in range(img_square_dimension):\n",
    "        temp_row = []\n",
    "        for col in range(img_square_dimension):\n",
    "            temp_row.append(img_colors[loop_count])\n",
    "            \n",
    "            loop_count += 1\n",
    "        img_matrix.append(temp_row)\n",
    "        \n",
    "    return img_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features Extraction\n",
    "def feature_extract(img, sampling_count, class_name):\n",
    "    glcm_component=[]\n",
    "    img_colors = get_img_colors(img, sampling_count)\n",
    "    img_3bit_colors = get_3bit_colors(img_colors)\n",
    "    img_matrix = get_img_matrix(img_3bit_colors)\n",
    "    glcm_matrix=greycomatrix(img_matrix, distances=[1], angles=[0], levels=12, symmetric=False, normed=False)\n",
    "    component = ['contrast', 'homogeneity', 'energy', 'correlation', 'ASM', 'dissimilarity']\n",
    "    for x in component:\n",
    "        glcm_component.append(greycoprops(glcm_matrix, x)[0][0])\n",
    "    glcm_component.append(class_name)\n",
    "    return(glcm_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelling\n",
    "def get_class_names(training_folder_path):\n",
    "    return os.listdir(training_folder_path)\n",
    "\n",
    "def make_a_model(class_name, features, learning_rate):\n",
    "    random_splitter = random.uniform(0, 1)\n",
    "    if(random_splitter <= learning_rate):\n",
    "        model[class_name].append(features)\n",
    "    else:\n",
    "        model_test[class_name].append(features)\n",
    "        \n",
    "def to_dataframe(model):\n",
    "    models = pd.DataFrame(model['cap'] + model['tulis'], columns=['contrast', 'homogeneity', 'energy', 'correlation', 'ASM', 'dissimilarity', 'class'])\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification\n",
    "def euclidian_distance(img_validate, img_model):\n",
    "    distance = 0.0\n",
    "    for i in range(len(img_validate)-1):\n",
    "        distance += (img_validate[i] - img_model[i])**2\n",
    "    return sqrt(distance)\n",
    "\n",
    "def knn(img, sampling_count, neighbor):\n",
    "    min_distance = []\n",
    "    class_min_distance = []\n",
    "    k = 0\n",
    "    img_validate = feature_extract(img, sampling_count)\n",
    "    distance = 0.0\n",
    "    for name_class in model:\n",
    "        for img_train in model[name_class]:\n",
    "            distance = euclidian_distance(img_validate, img_train)\n",
    "            \n",
    "            if(k<neighbor):\n",
    "                min_distance.append(distance)\n",
    "                class_min_distance.append(name_class)\n",
    "                k+=1\n",
    "            else:\n",
    "                for i in range (k):\n",
    "                    if(distance<min_distance[i]):\n",
    "                        min_distance[i] = distance\n",
    "                        class_min_distance[i]= name_class\n",
    "                        break\n",
    "                        \n",
    "    predict_class = max(set(class_min_distance), key=class_min_distance.count)\n",
    "    return predict_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "def validate(sampling_count):\n",
    "    right = 0.0;\n",
    "    total = 0.0;\n",
    "    accuracy = 0.0;\n",
    "    class_names = get_class_names(validation_folder_path)\n",
    "    for class_name in class_names:\n",
    "        validate_img_paths = glob.glob(validation_folder_path + class_name + '/' +img_type)\n",
    "        for validate_img_path in validate_img_paths:\n",
    "            img_validate = load_img(validate_img_path)\n",
    "            predict_class = knn(img_validate, sampling_count, neighbor)\n",
    "            class_image = class_name\n",
    "            if(predict_class == class_image):\n",
    "                right+=1\n",
    "            total +=1\n",
    "    accuracy = (right/total) * 100\n",
    "    print(\"Accuracy: \" + str(accuracy) +\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "\n",
    "def testing_knn(feature, neighbor):\n",
    "    min_distance = []\n",
    "    class_min_distance = []\n",
    "    k = 0\n",
    "    distance = 0.0\n",
    "    for name_class in model:\n",
    "        for img_train in model[name_class]:\n",
    "            distance = euclidian_distance(feature, img_train)\n",
    "            \n",
    "            if(k<neighbor):\n",
    "                min_distance.append(distance)\n",
    "                class_min_distance.append(name_class)\n",
    "                k+=1\n",
    "            else:\n",
    "                for i in range (k):\n",
    "                    if(distance<min_distance[i]):\n",
    "                        min_distance[i] = distance\n",
    "                        class_min_distance[i]= name_class\n",
    "                        break\n",
    "                        \n",
    "    predict_class = max(set(class_min_distance), key=class_min_distance.count)\n",
    "    return predict_class\n",
    "\n",
    "def testing_split(sampling_count):\n",
    "    right = 0.0;\n",
    "    total = 0.0;\n",
    "    accuracy = 0.0;\n",
    "    class_names = get_class_names(validation_folder_path)\n",
    "    for class_name in class_names:\n",
    "        for test_img in model_test[class_name]:\n",
    "            predict_class = testing_knn(test_img, neighbor)\n",
    "            class_image = class_name\n",
    "            if(predict_class == class_image):\n",
    "                right+=1\n",
    "            total +=1\n",
    "    accuracy = (right/total) * 100\n",
    "    print(\"Accuracy: \" + str(accuracy) +\"%\")\n",
    "    \n",
    "    \n",
    "def testing(sampling_count):\n",
    "    testing_img_paths = glob.glob(test_folder_path + '/' + img_type)\n",
    "    for testing_img_path in testing_img_paths:\n",
    "        imgs = load_img(testing_img_path)\n",
    "        predict_class = knn(imgs, sampling_count, neighbor)\n",
    "        print(\"Categorized as \" + predict_class)\n",
    "        plt.imshow(Image.open(testing_img_path))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed to make this model is 18.59775590000004 seconds.\n"
     ]
    }
   ],
   "source": [
    "#Training Testing\n",
    "\n",
    "learning_rate = 0.8\n",
    "sampling_count = 128\n",
    "img_type = '*.jpg'\n",
    "root_path = './'\n",
    "training_folder_path = root_path + 'glcm/training/'\n",
    "validation_folder_path = root_path + 'glcm/validation/'\n",
    "test_folder_path = root_path + 'glcm/test/'\n",
    "\n",
    "class_names = get_class_names(training_folder_path)\n",
    "\n",
    "for i in range(1):\n",
    "    for class_name in class_names:\n",
    "        training_img_paths = glob.glob(training_folder_path + class_name + '/' + img_type)\n",
    "        for training_img_path in training_img_paths:\n",
    "            training_img = load_img(training_img_path)\n",
    "            training_img_class_name = class_name\n",
    "            feature = feature_extract(training_img, sampling_count, training_img_class_name)\n",
    "            make_a_model(class_name, feature, learning_rate)\n",
    "        \n",
    "#     testing_split(sampling_count)\n",
    "    models = to_dataframe(model)\n",
    "    models_test = to_dataframe(model_test)\n",
    "\n",
    "\n",
    "\n",
    "time_modelling_stop = timeit.default_timer()\n",
    "print('Time elapsed to make this model is ' + str(time_modelling_stop - time_modelling_start) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contrast         0.498655\n",
       "homogeneity      0.004492\n",
       "energy           0.011133\n",
       "correlation      0.046286\n",
       "ASM              0.007225\n",
       "dissimilarity    0.047001\n",
       "dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tulis = models.loc[models['class'] == 'tulis']\n",
    "total_cap = models.loc[models['class'] == 'cap']\n",
    "mean= []\n",
    "variance = []\n",
    "for a in ['contrast', 'homogeneity', 'energy', 'correlation', 'ASM', 'dissimilarity']:\n",
    "    mean.append(models[a].mean())\n",
    "    variance.append(models[a].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2.034089707872138,\n",
       "  0.6821107182771711,\n",
       "  0.40702823099527624,\n",
       "  0.3769980496921079,\n",
       "  0.18863062077316067,\n",
       "  0.8497529973878559],\n",
       " [2.30667164868116,\n",
       "  0.015147573171397869,\n",
       "  0.023013564921964335,\n",
       "  0.058339783371230046,\n",
       "  0.02022692028959421,\n",
       "  0.18180489548007436])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (120-90)/(2*25)\n",
    "b = 1/(np.sqrt(2*3.14*25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14542091165335422"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = b * np.exp(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
